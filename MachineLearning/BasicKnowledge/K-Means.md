#K-means聚类算法
无监督学习:样本中没有给定y，只有样本x
聚类的目的是**找到每个样本x潜在的类别y**，并将同类别y的样本x放在一起

优点:(业界使用多的原因)
-   收敛快
-   只需要挑一个参数K
缺点:
-  k不好调
-  算法复杂度不容易控制(时间复杂度上界为O(n*k*t), 其中迭代次数t可能会比较多)
-  样本不平衡的时候效果不好
   > 在 k-means 中，我们假设各个 cluster 的先验概率是一样的，因此当样本不平衡的时候, 各个cluster的先验概率不同, 
   
-  对噪声和离群点敏感（容易导致中心点偏移）
-  不能发现非凸形状的簇，或大小差别很大的簇. 怎么办？加Kernel 。加什么Kernel ？慢慢试
-  不怎么robust

过程:
1. 随机选取k个中心点（cluster centroids）为$$\mu_{1}, \mu_{2},...$$
2. 重复下面过程直到收敛 {
对于每一个样例i，根据其到各个中心的距离, 计算其应该属于的类   (给每个样本假设类别y, 也就是**隐含变量**, EM中的Expectation)
更新中心点  (**极大似然估计**此时的参数, EM中的Maximization)
}
